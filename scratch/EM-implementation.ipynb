{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a19261",
   "metadata": {},
   "source": [
    "# In class EM implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3fa61d",
   "metadata": {},
   "source": [
    "## Stopping iteration\n",
    "\n",
    "Need to stop somewhere, keep track how much it is improving when it slows down then you stop optimizing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679728e2",
   "metadata": {},
   "source": [
    "How would actually calculate?\n",
    "\n",
    "- Each sequences have is length $L$\n",
    "- How to calculate things we need given the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee7b720",
   "metadata": {},
   "source": [
    "## Computing posteriors (E step)\n",
    "\n",
    "- Posteriors goes into M step\n",
    "- At some point need to calculate post for each base for each sequence\n",
    "    - Already init $\\lambda_{l}$ and $\\Psi_{l}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c78cb9",
   "metadata": {},
   "source": [
    "- Could do nested for loop but not efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b929a011",
   "metadata": {},
   "source": [
    "In current model each base is sampled independently so each time you see an A you will have same value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e80492",
   "metadata": {},
   "source": [
    "$ P(C_{ij}=1|X_{ij}=A) = \\frac{\\lambda_{1}\\Psi^{1}_{A}}{\\lambda_{0}\\Psi^{0}_{A} + \\lambda_{1}\\Psi^{1}_{A}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2204fda",
   "metadata": {},
   "source": [
    "For next class write code to calculate the posteriors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff5b72",
   "metadata": {},
   "source": [
    "$C_{i,j}$ converted into $C_{i, j, l}$ because $C_{i, j}$ could take on multiple values due to multiple models? Want to reduce $C$ to either zero or one when converting to expectation (?). \n",
    "\n",
    "In the E step $q = P(C | X)$ and therefore depends on what value X we have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe74c15",
   "metadata": {},
   "source": [
    "## For Thursday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d9f1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41194451",
   "metadata": {},
   "source": [
    "Initialize the model parameters $\\theta$ which include $\\lambda_{0}, \\lambda_{1}, \\Psi^{0}_{k}$ and $\\Psi^{1}_{k}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc9f4448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l0': 0.03705496470442482,\n",
       " 'l1': 0.9629450352955752,\n",
       " 'psi0': array([0.89698044, 0.0187848 , 0.4707884 , 0.17963004]),\n",
       " 'psi1': array([0.56367798, 0.56942416, 0.9238641 , 0.75458959])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_params():\n",
    "    \n",
    "    lambda_0 = np.random.uniform()\n",
    "    lambda_1 = 1 - lambda_0\n",
    "    \n",
    "    def init_psi():\n",
    "        psi = np.random.uniform(size=(4))\n",
    "        psi_norm = psi / psi.sum()\n",
    "        return psi\n",
    "    \n",
    "    psi_0 = init_psi()\n",
    "    psi_1 = init_psi()\n",
    "    \n",
    "    return {\n",
    "        'l0': lambda_0, 'l1': lambda_1, 'psi0': psi_0, 'psi1': psi_1\n",
    "    }\n",
    "\n",
    "theta_0 = init_params()\n",
    "theta_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4e43f0",
   "metadata": {},
   "source": [
    "Calculate posterior probability array. Gives the probability $C=1$ given the identity of a specific nucleotide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ae97c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9422987247226866, 0.9987321594690878, 0.9807678086255173, 0.990922779498142]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def post_probs(theta_0): \n",
    "    return [\n",
    "        (\n",
    "            (theta_0['l1']*theta_0['psi1'][i]) / \n",
    "            (theta_0['l0']*theta_0['psi0'][i] + theta_0['l1']*theta_0['psi1'][i])\n",
    "        ) for i in range(4)\n",
    "    ]\n",
    "\n",
    "probs = post_probs(theta_0)  # probability of Cij == 1 given the identity of each nucleotide\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d9651a",
   "metadata": {},
   "source": [
    "Code from sequence reader assignment to read in Quon enhancer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cdb990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seq_file(filepath):\n",
    "    with open(filepath) as handle:\n",
    "        return [s.upper().strip() for s in handle]\n",
    "\n",
    "def nuc_to_one_hot(nuc):\n",
    "    # Convert nucleotide to the index in one hot encoded array\n",
    "    # that should be hot (==1)\n",
    "    upper_nuc = nuc.upper()\n",
    "    mapping = {'A': 0, 'T': 1, 'G': 2, 'C': 3}\n",
    "    return mapping[upper_nuc]\n",
    "\n",
    "def make_matrix(seqs):\n",
    "    # input an iterable of sequences and return one hot matrix\n",
    "    num_seqs, length = len(seqs), len(seqs[0])\n",
    "    # assume all sequences are the same length\n",
    "    matrix = np.zeros((num_seqs, length, 4))\n",
    "    for i, each_seq in enumerate(seqs):\n",
    "        for j, each_nuc in enumerate(each_seq):\n",
    "            hot_index = nuc_to_one_hot(each_nuc)\n",
    "            matrix[i][j][hot_index] = 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ff1310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_path = '../assignments/data/sequence.padded.txt'\n",
    "seqs = read_seq_file(seqs_path)\n",
    "seq_matrix = make_matrix(seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15a21dc",
   "metadata": {},
   "source": [
    "Multiply each one-hot encoded matrix by the posterior matrix. Since only one value in seq matrix is non-zero and at the same index as the posterior multiplying the two together will give 3D matrix that hold posterior probibilities for each base. The array at positions $X_{ij}$ could be reduced to single values by summing in that format makes more sense in the actual E step implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58b5c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_probs = seq_matrix * probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a9837fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.94229872, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.99873216, 0.        , 0.        ],\n",
       "        [0.94229872, 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.99092278],\n",
       "        [0.        , 0.        , 0.98076781, 0.        ],\n",
       "        [0.        , 0.99873216, 0.        , 0.        ]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.99092278],\n",
       "        [0.94229872, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.99873216, 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.99092278],\n",
       "        [0.94229872, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.99873216, 0.        , 0.        ]],\n",
       "\n",
       "       [[0.94229872, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.98076781, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.99092278],\n",
       "        ...,\n",
       "        [0.94229872, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.99092278],\n",
       "        [0.        , 0.        , 0.        , 0.99092278]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.99092278],\n",
       "        [0.        , 0.        , 0.        , 0.99092278],\n",
       "        [0.94229872, 0.        , 0.        , 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.98076781, 0.        ],\n",
       "        [0.        , 0.        , 0.98076781, 0.        ],\n",
       "        [0.        , 0.        , 0.98076781, 0.        ]],\n",
       "\n",
       "       [[0.94229872, 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.98076781, 0.        ],\n",
       "        [0.        , 0.        , 0.98076781, 0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.99873216, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.98076781, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.99092278]],\n",
       "\n",
       "       [[0.        , 0.        , 0.        , 0.99092278],\n",
       "        [0.        , 0.99873216, 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.99092278],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , 0.99092278],\n",
       "        [0.        , 0.        , 0.        , 0.99092278],\n",
       "        [0.        , 0.        , 0.        , 0.99092278]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c071d",
   "metadata": {},
   "source": [
    "Version of matrix were we take sum of each array at $X_{ij}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aea4a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94229872, 0.99873216, 0.94229872, ..., 0.99092278, 0.98076781,\n",
       "        0.99873216],\n",
       "       [0.99092278, 0.94229872, 0.99873216, ..., 0.99092278, 0.94229872,\n",
       "        0.99873216],\n",
       "       [0.94229872, 0.98076781, 0.99092278, ..., 0.94229872, 0.99092278,\n",
       "        0.99092278],\n",
       "       ...,\n",
       "       [0.99092278, 0.99092278, 0.94229872, ..., 0.98076781, 0.98076781,\n",
       "        0.98076781],\n",
       "       [0.94229872, 0.98076781, 0.98076781, ..., 0.99873216, 0.98076781,\n",
       "        0.99092278],\n",
       "       [0.99092278, 0.99873216, 0.99092278, ..., 0.99092278, 0.99092278,\n",
       "        0.99092278]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_probs_sum = base_probs.sum(axis=2)\n",
    "base_probs_sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
